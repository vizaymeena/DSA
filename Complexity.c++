/*
 Time Complexity :-
                 
            Time complexity describes how the runtime of an algorithm grows as the input size (n) increases. It helps analyze the efficiency of an algorithm and compare different approaches.
            
            Ex - Sorting an array of 10 elements takes 1 second
                 Sorting 1,000,000 elements takes 10,000 seconds
                 The time complexity tells us how runtime increases as input grows



Big O Notation :- Big O Notation represents the upper bound of an algorithm's time complexity 
                  (worst-case scenario). It describes how fast the execution time increases with input size.


            //  Some Common Big O Notation .

                Big O   	Name            	    Example Algorithm	                     Performance

                O(1)	    Constant Time	        Accessing an array element arr[i]	    ğŸ”¥ Fast (Best)
                O(log n)	Logarithmic Time	    Binary Search	                        âš¡ Very Fast
                O(n)	    Linear Time	            Traversing an array (for loop)	         ğŸš€ Good
                O(n log n)	Linearithmic Time	    Merge Sort, QuickSort (best case)	    âš¡ Moderate
                O(nÂ²)	    Quadratic Time	        Bubble Sort, Insertion Sort         	ğŸŒ Slow
                O(2â¿)	    Exponential Time    	Recursive Fibonacci	                    ğŸ¢ Very Slow
                O(n!)	    Factorial Time	        Traveling Salesman Problem (TSP)	    ğŸŒğŸš€ Extremely Slow



Asympotic Notation : Describe the growth of an algorithm time or space complexity in releation to input size
Types of Asympotic Notation -

1. Big       (o)            Worst case
2. Omega     (omega sign)   Best case
3. Theta     (0)            Average case
        




*/